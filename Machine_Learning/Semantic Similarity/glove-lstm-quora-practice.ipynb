{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/quora-question-pairs/train.csv.zip\n/kaggle/input/quora-question-pairs/sample_submission.csv.zip\n/kaggle/input/quora-question-pairs/test.csv\n/kaggle/input/quora-question-pairs/test.csv.zip\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nimport tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/quora-question-pairs/train.csv.zip')\n","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"   id  qid1  qid2                                          question1  \\\n0   0     1     2  What is the step by step guide to invest in sh...   \n1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n2   2     5     6  How can I increase the speed of my internet co...   \n3   3     7     8  Why am I mentally very lonely? How can I solve...   \n4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n\n                                           question2  is_duplicate  \n0  What is the step by step guide to invest in sh...             0  \n1  What would happen if the Indian government sto...             0  \n2  How can Internet speed be increased by hacking...             0  \n3  Find the remainder when [math]23^{24}[/math] i...             0  \n4            Which fish would survive in salt water?             0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>6</td>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>10</td>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('../input/quora-question-pairs/test.csv.zip')","execution_count":5,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3147: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"  test_id                                          question1  \\\n0       0  How does the Surface Pro himself 4 compare wit...   \n1       1  Should I have a hair transplant at age 24? How...   \n2       2  What but is the best way to send money from Ch...   \n3       3                        Which food not emulsifiers?   \n4       4                   How \"aberystwyth\" start reading?   \n\n                                           question2  \n0  Why did Microsoft choose core m3 and not core ...  \n1        How much cost does hair transplant require?  \n2                      What you send money to China?  \n3                                  What foods fibre?  \n4                     How their can I start reading?  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test_id</th>\n      <th>question1</th>\n      <th>question2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>How does the Surface Pro himself 4 compare wit...</td>\n      <td>Why did Microsoft choose core m3 and not core ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Should I have a hair transplant at age 24? How...</td>\n      <td>How much cost does hair transplant require?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>What but is the best way to send money from Ch...</td>\n      <td>What you send money to China?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Which food not emulsifiers?</td>\n      <td>What foods fibre?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>How \"aberystwyth\" start reading?</td>\n      <td>How their can I start reading?</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Keras text preprocessing\nMAX_NB_WORDS = 200000\ntokenizer = Tokenizer(num_words = MAX_NB_WORDS)\ntokenizer.fit_on_texts(list(df['question1'].values.astype(str))+list(df['question2'].values.astype(str)))","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_testq1 = test_data.iloc[:400001,1:2].values\nX_testq2 = test_data.iloc[:400001, 2:].values\n\nX_train_q1 = tokenizer.texts_to_sequences(df['question1'].values.astype(str))\nX_train_q1 = pad_sequences(X_train_q1, maxlen = 30, padding='post')\n\nX_train_q2 = tokenizer.texts_to_sequences(df['question2'].values.astype(str))\nX_train_q2 = pad_sequences(X_train_q2, maxlen = 30, padding='post')\n\nX_test_q1 = tokenizer.texts_to_sequences(X_testq1.ravel())\nX_test_q1 = pad_sequences(X_test_q1,maxlen = 30, padding='post')\n\nX_test_q2 = tokenizer.texts_to_sequences(X_testq2.astype(str).ravel())\nX_test_q2 = pad_sequences(X_test_q2, maxlen = 30, padding='post')","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_index = tokenizer.word_index","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_index = {}\nwith open('../input/glove-global-vectors-for-word-representation/glove.6B.200d.txt','r') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        vectors = np.asarray(values[1:], 'float32')\n        embedding_index[word] = vectors\n    f.close()","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_matrix = np.random.random((len(word_index)+1, 200))\nfor word, i in word_index.items():\n    embedding_vector = embedding_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LSTM\n# Model for Q1\nimport tensorflow as tf\nfrom tensorflow.keras.layers import BatchNormalization\nmodel_q1 = tf.keras.Sequential()\nmodel_q1.add(Embedding(input_dim = len(word_index)+1,\n                       output_dim = 200,\n                      weights = [embedding_matrix],\n                      input_length = 30))\nmodel_q1.add(LSTM(128, activation = 'tanh', return_sequences = True))\nmodel_q1.add(Dropout(0.2))\nmodel_q1.add(LSTM(128, return_sequences = True))\nmodel_q1.add(LSTM(128))\nmodel_q1.add(Dense(60, activation = 'tanh'))\nmodel_q1.add(Dense(2, activation = 'sigmoid'))","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model for Q2\nmodel_q2 = tf.keras.Sequential()\nmodel_q2.add(Embedding(input_dim = len(word_index)+1,\n                       output_dim = 200,\n                      weights = [embedding_matrix],\n                      input_length = 30))\nmodel_q2.add(LSTM(128, activation = 'tanh', return_sequences = True))\nmodel_q2.add(Dropout(0.2))\nmodel_q2.add(LSTM(128, return_sequences = True))\nmodel_q2.add(LSTM(128))\nmodel_q2.add(Dense(60, activation = 'tanh'))\nmodel_q2.add(Dense(2, activation = 'sigmoid'))","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merging the output of the two models,i.e, model_q1 and model_q2\nmergedOut = Multiply()([model_q1.output, model_q2.output])\n\nmergedOut = Flatten()(mergedOut)\nmergedOut = Dense(100, activation = 'relu')(mergedOut)\nmergedOut = Dropout(0.2)(mergedOut)\nmergedOut = Dense(50, activation = 'relu')(mergedOut)\nmergedOut = Dropout(0.2)(mergedOut)\nmergedOut = Dense(2, activation = 'sigmoid')(mergedOut)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nY_train = df.iloc[:,5:].values","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_model = Model([model_q1.input, model_q2.input], mergedOut)\nnew_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',\n                 metrics = ['accuracy'])\nhistory = new_model.fit([X_train_q1,X_train_q2],Y_train, batch_size = 2000, epochs = 10)","execution_count":18,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n203/203 [==============================] - 149s 684ms/step - loss: 0.6616 - accuracy: 0.6278\nEpoch 2/10\n203/203 [==============================] - 140s 688ms/step - loss: 0.5780 - accuracy: 0.6944\nEpoch 3/10\n203/203 [==============================] - 140s 688ms/step - loss: 0.5149 - accuracy: 0.7472\nEpoch 4/10\n203/203 [==============================] - 139s 685ms/step - loss: 0.4753 - accuracy: 0.7695\nEpoch 5/10\n203/203 [==============================] - 139s 685ms/step - loss: 0.4498 - accuracy: 0.7811\nEpoch 6/10\n203/203 [==============================] - 140s 690ms/step - loss: 0.4190 - accuracy: 0.7975\nEpoch 7/10\n203/203 [==============================] - 139s 686ms/step - loss: 0.3969 - accuracy: 0.8076\nEpoch 8/10\n203/203 [==============================] - 140s 687ms/step - loss: 0.3742 - accuracy: 0.8189\nEpoch 9/10\n203/203 [==============================] - 140s 687ms/step - loss: 0.3575 - accuracy: 0.8264\nEpoch 10/10\n203/203 [==============================] - 139s 686ms/step - loss: 0.3386 - accuracy: 0.8368\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = new_model.predict([X_test_q1, X_test_q2], batch_size=2000, verbose=1)","execution_count":19,"outputs":[{"output_type":"stream","text":"201/201 [==============================] - 13s 57ms/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred.shape)\nprint(20*\"-\")\nprint(y_pred)","execution_count":23,"outputs":[{"output_type":"stream","text":"float32\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}