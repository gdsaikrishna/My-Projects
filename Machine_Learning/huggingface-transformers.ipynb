{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import pipeline\nclassifier = pipeline('sentiment-analysis')#Sentiment analysis: is a text positive or negative?","execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8705aae062fa4302acef06e905a97f14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cb5a01d8b4d42c5bd7d9a9702bd19fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe16c8426c824fd993f8de872ce60341"}},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Text Classification\n# a pretrained model and its tokenizer are downloaded and cached. \nclassifier('We are very happy to show you the Transformers library.')\n#By default the model downloaded for this pipeline is “distilbert-base-uncased-finetuned-sst-2-english”. ","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"[{'label': 'POSITIVE', 'score': 0.999799370765686}]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import pipeline, set_seed\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Text Generation\ngenerator = pipeline('text-generation', model='gpt2')\nset_seed(42)\ngenerator(\"Hello, I like to play cricket,\", max_length=60, num_return_sequences=7)","execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a681913ee9a4616ba6e687004068d50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22e9add0dd8d4bb4a291c469c09df179"}},"metadata":{}},{"output_type":"stream","text":"Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0abc8d4870044c51b53a94acdf809abb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"963b71c0a57c4661932307d099ccaff0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"389359e5d6434a6399528f4f3670a90d"}},"metadata":{}},{"output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","name":"stderr"},{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"[{'generated_text': 'Hello, I like to play cricket, I always will be. I know the same thing about cricket today,\" he said.He also said that he had enjoyed playing for many years before he joined Vodafone. \"As far as I\\'m concerned this is the only sport in our history where'},\n {'generated_text': 'Hello, I like to play cricket, and in any other sport that involves a lot of effort, they\\'ll be better at getting the ball over the top.\\n\\n\"They will also always get the ball down the side of the batsman when called up, but I guess when I was younger'},\n {'generated_text': 'Hello, I like to play cricket, it\\'s a family sport,\" he said.\\n\\n\"It\\'s an honour to be playing cricket with our colleagues every day. I loved the way it was played for me when I was young.\\n\\n\"My wife played as a teacher in her native'},\n {'generated_text': \"Hello, I like to play cricket, especially to the left.\\n\\nWhen you're on the road – you're at home – you can feel that something is not right with your body – and I wouldn't expect much of the same at work. But I am happy that my body is not\"},\n {'generated_text': 'Hello, I like to play cricket, and I like to enjoy cricket. I like to see it all grow up.\" He stopped and looked into my eyes, \"You want to stop, aren\\'t you?\"\\n\\n\"Of course it\\'s not,\" I said, trying to make it to the'},\n {'generated_text': 'Hello, I like to play cricket, but I don\\'t have a good sense of what I\\'m doing, what I\\'m doing. When I was at London\\'s Colney Sports Centre, there was a massive crowd who were coming for cricket matches and I\\'d catch a game.\\n\\n\"If'},\n {'generated_text': \"Hello, I like to play cricket, I like to be a little bit adventurous. But when I get into the sport and I have got a little bit of money but there's definitely no easy way to do it and I'll do it that way. But I always have my mind set on being\"}]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator(\"Football is a\", max_length=60, num_return_sequences=7)","execution_count":6,"outputs":[{"output_type":"stream","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","name":"stderr"},{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"[{'generated_text': \"Football is a non-profit organization that makes the world a better place, but a lot of your knowledge comes along with it, from experience and you need to keep that in mind when you play. So that's one of our most important requirements.\\n\\n\\nHow much does it cost?\\n\\n\"},\n {'generated_text': \"Football is a game and a tradition of supporting us that allows us to celebrate our sports. And I know what you do is you cheer them on out back. But I know what you don't do is go to your locker room and try to get everyone to have a good game and feel good about\"},\n {'generated_text': \"Football is a franchise of the college game, but that doesn't preclude them from participating at the University of California–Berkeley.\\n\\nIn April of 2014, the University announced plans to invest $3 million to support the university's expansion. In January, they added a 3,500-seat\"},\n {'generated_text': 'Football is a unique opportunity for clubs of all sizes to offer a fantastic, high-quality, competitive, and entertaining football simulation, providing a team of professionals with both competitive and casual environment.\\n\\nWe have been designed specifically for teams of every age, experience and talent, and offer a simple and'},\n {'generated_text': 'Football is a great program, which needs help from its coaches. I personally think that the two programs, the former Florida Gators and the latter Alabama, are better than one another and will continue to grow and improve as a program. I think the programs need some time as well to move forward. \"'},\n {'generated_text': 'Football is a fun sport, it\\'s hard to do it better in all the wrong ways,\" said Kollman, who is running through the course of doing his first run for the American Volleyball Association. \"I don\\'t think there\\'s ever been any place in the program like it.'},\n {'generated_text': \"Football is a high-stress industry, especially when it comes to high-stakes sports. So the next time you're out and about, it's a good idea to stay there. The league-wide meetings will come and go as a whole, but you won't get to speak to anyone on\"}]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Question-Answering\nquestion_answer_model = pipeline('question-answering')\ncontext = r'''\nKalam was elected as the 11th President of India in 2002 with the support of \nboth the ruling Bharatiya Janata Party and the then-opposition Indian National Congress. \nWidely referred to as the \"People's President\",[6] he returned to his civilian life of education, \nwriting and public service after a single term. He was a recipient of several prestigious awards,\nincluding the Bharat Ratna, India's highest civilian honour.\n'''\nresult = question_answer_model(question = \"What are the awards received by Kalam?\", context = context)\nprint(f\"Answer : '{result['answer']}'\")","execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/473 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"215435f9aeb443019bce9b4b97546ec0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/261M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"543a7761fead42b7a6448cfb439c4125"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30513e733c5b410ea66a6b3aeb48ffd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa495047a38b4cc583967e15a36efc29"}},"metadata":{}},{"output_type":"stream","text":"Answer : 'Bharat Ratna'\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Text Prediction\nunmasker = pipeline('fill-mask', model='bert-base-cased')\nunmasker(\"Let's go to [MASK].\")","execution_count":9,"outputs":[{"output_type":"stream","text":"Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","name":"stderr"},{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"[{'sequence': \"[CLS] Let's go to bed. [SEP]\",\n  'score': 0.3139238953590393,\n  'token': 1908,\n  'token_str': 'bed'},\n {'sequence': \"[CLS] Let's go to sleep. [SEP]\",\n  'score': 0.20112983882427216,\n  'token': 2946,\n  'token_str': 'sleep'},\n {'sequence': \"[CLS] Let's go to dinner. [SEP]\",\n  'score': 0.05540060997009277,\n  'token': 4014,\n  'token_str': 'dinner'},\n {'sequence': \"[CLS] Let's go to work. [SEP]\",\n  'score': 0.05016692727804184,\n  'token': 1250,\n  'token_str': 'work'},\n {'sequence': \"[CLS] Let's go to school. [SEP]\",\n  'score': 0.02645091712474823,\n  'token': 1278,\n  'token_str': 'school'}]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Text Summarization\n#Summarization is currently supported by Bart and T5.\n\nsummarizer = pipeline(\"summarization\")\n\nARTICLE = \"\"\"The Apollo program, also known as Project Apollo, was the third United States human spaceflight program carried out by the National Aeronautics and Space Administration (NASA), which accomplished landing the first humans on the Moon from 1969 to 1972.\nFirst conceived during Dwight D. Eisenhower's administration as a three-man spacecraft to follow the one-man Project Mercury which put the first Americans in space,\nApollo was later dedicated to President John F. Kennedy's national goal of \"landing a man on the Moon and returning him safely to the Earth\" by the end of the 1960s, which he proposed in a May 25, 1961, address to Congress. \nProject Mercury was followed by the two-man ProjectGemini (1962–66). \nThe first manned flight of Apollo was in 1968.\nApollo ran from 1961 to 1972, and was supported by the two-man Gemini program which ran concurrently with it from 1962 to 1966. \nGemini missions developed some of the space travel techniques that were necessary for the success of the Apollo missions.\nApollo used Saturn family rockets as launch vehicles. \nApollo/Saturn vehicles were also used for an Apollo Applications Program, which consisted of Skylab, a space station that supported three manned missions in 1973–74, and the Apollo–Soyuz Test Project, a joint Earth orbit mission with the Soviet Union in 1975.\n \"\"\"\n\nsummary=summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False)[0]\n\nprint(summary['summary_text'])","execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4628dba8840c4b05ae5c963e115c182e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2f5696478224c20a66d1501311935ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13b44ca6dcdc460b8b46e0e38d7bf35d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa89c1bd8eb7440a933b0003cc12c495"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fa0d13600994eeb9e8a237cc6f965a0"}},"metadata":{}},{"output_type":"stream","text":" The first manned flight of Apollo ran from 1961 to 1972 . The Apollo program was followed by the two-man ProjectGemini . It was the third mission to land on the Moon .\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# English to German\ntranslator_ger = pipeline(\"translation_en_to_de\")\nprint(\"German: \",translator_ger(\"Success is a lousy teacher. It seduces smart people into thinking they can't lose.\", max_length=40)[0]['translation_text'])\n\n# English to French\ntranslator_fr = pipeline('translation_en_to_fr')\nprint(\"French: \",translator_fr(\"Success is a lousy teacher. It seduces smart people into thinking they can't lose.\",  max_length=40)[0]['translation_text'])","execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2386ef16c5074019b8f47de2451399f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2f5f7f312644168946206911b465948"}},"metadata":{}},{"output_type":"stream","text":"Some weights of the model checkpoint at t5-base were not used when initializing T5Model: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n- This IS expected if you are initializing T5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing T5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a08d0cf0ec7a49cdb71f29461d4eae77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34ba513850bb4a059dfc2c9b6fc06423"}},"metadata":{}},{"output_type":"stream","text":"Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","name":"stderr"},{"output_type":"stream","text":"German:  Erfolg ist ein schlechter Lehrer, der intelligente Menschen dazu verleitet, zu glauben, sie könnten nicht verlieren.\n","name":"stdout"},{"output_type":"stream","text":"Some weights of the model checkpoint at t5-base were not used when initializing T5Model: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n- This IS expected if you are initializing T5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing T5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","name":"stderr"},{"output_type":"stream","text":"French:  Le succès est un enseignant malheureux qui séduit les gens intelligents pour qu'ils pensent qu'ils ne peuvent pas perdre.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp_token_class = pipeline('ner') \nnlp_token_class('Ronaldo was born in 1985, he plays for Juventus and Portugal. ')","execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/998 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"846afb9351ab4dfcb6ff96a47697be06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"179352f0b6e244229d03cd83bf905045"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a64351f674e4f06af892d279d1ba22d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/60.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee56a6db529744f0b5322c06da46b0f7"}},"metadata":{}},{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"[{'word': 'Ronald',\n  'score': 0.9978647828102112,\n  'entity': 'I-PER',\n  'index': 1},\n {'word': '##o', 'score': 0.99903804063797, 'entity': 'I-PER', 'index': 2},\n {'word': 'Juventus',\n  'score': 0.9977495670318604,\n  'entity': 'I-ORG',\n  'index': 11},\n {'word': 'Portugal',\n  'score': 0.9991246461868286,\n  'entity': 'I-LOC',\n  'index': 13}]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Zero-Shot Learning\n#Zero-Shot learning method aims to solve a task without receiving any example of that task at training phase.\nclassifier_zsl = pipeline(\"zero-shot-classification\")\n\nsequence_to_classify = \"Bill gates founded a company called Microsoft in the year 1975\"\ncandidate_labels = [\"Europe\", \"Sports\",'Leadership','business', \"politics\",\"startup\"]\nclassifier_zsl(sequence_to_classify, candidate_labels)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}