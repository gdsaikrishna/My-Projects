{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Download the data\n!!curl -O http://www.manythings.org/anki/fra-eng.zip\n!!unzip fra-eng.zip","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"['Archive:  fra-eng.zip',\n '  inflating: _about.txt              ',\n '  inflating: fra.txt                 ']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Configuration\nbatch_size = 64\nepochs = 100\nlatent_dim = 256\nnum_samples = 10000\ndata_path = 'fra.txt'","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prepare the data fron the file\ninput_texts = []\ntarget_texts = []\ninput_characters = set()\ntarget_characters = set()\nwith open(data_path, \"r\", encoding=\"utf-8\") as f:\n    lines = f.read().split(\"\\n\")\nfor line in lines[: min(num_samples, len(lines) - 1)]:\n    input_text, target_text, _ = line.split(\"\\t\")\n    # We use \"tab\" as the \"start sequence\" character\n    # for the targets, and \"\\n\" as \"end sequence\" character.\n    target_text = \"\\t\" + target_text + \"\\n\"\n    input_texts.append(input_text)\n    target_texts.append(target_text)\n    for char in input_text:\n        if char not in input_characters:\n            input_characters.add(char)\n    for char in target_text:\n        if char not in target_characters:\n            target_characters.add(char)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_characters = sorted(list(input_characters))\ntarget_characters = sorted(list(target_characters))\nnum_encoder_tokens = len(input_characters)\nnum_decoder_tokens = len(target_characters)\nmax_encoder_seq_length = max([len(txt) for txt in input_texts])\nmax_decoder_seq_length = max([len(txt) for txt in target_texts])\n\nprint(\"Number of samples:\", len(input_texts))\nprint(\"Number of unique input tokens:\", num_encoder_tokens)\nprint(\"Number of unique output tokens:\", num_decoder_tokens)\nprint(\"Max sequence length for inputs:\", max_encoder_seq_length)\nprint(\"Max sequence length for outputs:\", max_decoder_seq_length)","execution_count":6,"outputs":[{"output_type":"stream","text":"Number of samples: 10000\nNumber of unique input tokens: 71\nNumber of unique output tokens: 93\nMax sequence length for inputs: 15\nMax sequence length for outputs: 59\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(input_characters)","execution_count":7,"outputs":[{"output_type":"stream","text":"[' ', '!', '\"', '$', '%', '&', \"'\", ',', '-', '.', '0', '1', '2', '3', '5', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'é']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(target_characters)","execution_count":8,"outputs":[{"output_type":"stream","text":"['\\t', '\\n', ' ', '!', '$', '%', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '5', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xa0', '«', '»', 'À', 'Ç', 'É', 'Ê', 'à', 'â', 'ç', 'è', 'é', 'ê', 'î', 'ï', 'ô', 'ù', 'û', 'œ', '\\u2009', '’', '\\u202f']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\ntarget_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n\nencoder_input_data = np.zeros(\n    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n)\ndecoder_input_data = np.zeros(\n    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n)\ndecoder_target_data = np.zeros(\n    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n    for t, char in enumerate(input_text):\n        encoder_input_data[i, t, input_token_index[char]] = 1.0\n    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n    for t, char in enumerate(target_text):\n        # decoder_target_data is ahead of decoder_input_data by one timestep\n        decoder_input_data[i, t, target_token_index[char]] = 1.0\n        if t > 0:\n            # decoder_target_data will be ahead by one timestep\n            # and will not include the start character.\n            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating our model\nencoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\nencoder = keras.layers.LSTM(latent_dim, return_state=True)\nencoder_outputs, state_h, state_c = encoder(encoder_inputs)\n\nencoder_states = [state_h, state_c]\n\ndecoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\ndecoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\ndecoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\ndecoder_outputs = decoder_dense(decoder_outputs)\n\nmodel = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n)\nmodel.fit(\n    [encoder_input_data, decoder_input_data],\n    decoder_target_data,\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_split=0.2,\n)\n# Save model\nmodel.save(\"s2s\")","execution_count":12,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n125/125 [==============================] - 8s 23ms/step - loss: 1.8684 - accuracy: 0.7014 - val_loss: 1.0934 - val_accuracy: 0.7012\nEpoch 2/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.9206 - accuracy: 0.7473 - val_loss: 0.9222 - val_accuracy: 0.7523\nEpoch 3/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.7797 - accuracy: 0.7895 - val_loss: 0.7986 - val_accuracy: 0.7804\nEpoch 4/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.6738 - accuracy: 0.8124 - val_loss: 0.7144 - val_accuracy: 0.7979\nEpoch 5/100\n125/125 [==============================] - 2s 15ms/step - loss: 0.6258 - accuracy: 0.8258 - val_loss: 0.8632 - val_accuracy: 0.7673\nEpoch 6/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.6797 - accuracy: 0.8101 - val_loss: 0.7004 - val_accuracy: 0.7982\nEpoch 7/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.5928 - accuracy: 0.8281 - val_loss: 0.6645 - val_accuracy: 0.8069\nEpoch 8/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.5624 - accuracy: 0.8352 - val_loss: 0.6413 - val_accuracy: 0.8123\nEpoch 9/100\n125/125 [==============================] - 2s 15ms/step - loss: 0.5452 - accuracy: 0.8401 - val_loss: 0.6235 - val_accuracy: 0.8171\nEpoch 10/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.5367 - accuracy: 0.8417 - val_loss: 0.6112 - val_accuracy: 0.8199\nEpoch 11/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.5166 - accuracy: 0.8478 - val_loss: 0.5960 - val_accuracy: 0.8247\nEpoch 12/100\n125/125 [==============================] - 2s 13ms/step - loss: 0.5021 - accuracy: 0.8516 - val_loss: 0.5839 - val_accuracy: 0.8311\nEpoch 13/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.4916 - accuracy: 0.8551 - val_loss: 0.5679 - val_accuracy: 0.8346\nEpoch 14/100\n125/125 [==============================] - 2s 13ms/step - loss: 0.4795 - accuracy: 0.8582 - val_loss: 0.5635 - val_accuracy: 0.8351\nEpoch 15/100\n125/125 [==============================] - 2s 13ms/step - loss: 0.4661 - accuracy: 0.8618 - val_loss: 0.5507 - val_accuracy: 0.8389\nEpoch 16/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.4524 - accuracy: 0.8660 - val_loss: 0.5425 - val_accuracy: 0.8412\nEpoch 17/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.4488 - accuracy: 0.8669 - val_loss: 0.5390 - val_accuracy: 0.8420\nEpoch 18/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.4397 - accuracy: 0.8692 - val_loss: 0.5290 - val_accuracy: 0.8451\nEpoch 19/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.4312 - accuracy: 0.8720 - val_loss: 0.5212 - val_accuracy: 0.8471\nEpoch 20/100\n125/125 [==============================] - 2s 13ms/step - loss: 0.4201 - accuracy: 0.8750 - val_loss: 0.5119 - val_accuracy: 0.8497\nEpoch 21/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.4141 - accuracy: 0.8766 - val_loss: 0.5063 - val_accuracy: 0.8515\nEpoch 22/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.3999 - accuracy: 0.8805 - val_loss: 0.5049 - val_accuracy: 0.8509\nEpoch 23/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.3997 - accuracy: 0.8806 - val_loss: 0.4984 - val_accuracy: 0.8527\nEpoch 24/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.3890 - accuracy: 0.8835 - val_loss: 0.4918 - val_accuracy: 0.8561\nEpoch 25/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.3807 - accuracy: 0.8859 - val_loss: 0.4901 - val_accuracy: 0.8564\nEpoch 26/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.3719 - accuracy: 0.8887 - val_loss: 0.4815 - val_accuracy: 0.8600\nEpoch 27/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.3658 - accuracy: 0.8910 - val_loss: 0.4785 - val_accuracy: 0.8597\nEpoch 28/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.3596 - accuracy: 0.8922 - val_loss: 0.4741 - val_accuracy: 0.8614\nEpoch 29/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.3502 - accuracy: 0.8956 - val_loss: 0.4711 - val_accuracy: 0.8619\nEpoch 30/100\n125/125 [==============================] - 2s 15ms/step - loss: 0.3412 - accuracy: 0.8975 - val_loss: 0.4671 - val_accuracy: 0.8633\nEpoch 31/100\n125/125 [==============================] - 2s 15ms/step - loss: 0.3365 - accuracy: 0.8990 - val_loss: 0.4650 - val_accuracy: 0.8637\nEpoch 32/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.3299 - accuracy: 0.9010 - val_loss: 0.4621 - val_accuracy: 0.8654\nEpoch 33/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.3230 - accuracy: 0.9027 - val_loss: 0.4587 - val_accuracy: 0.8665\nEpoch 34/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.3168 - accuracy: 0.9052 - val_loss: 0.4558 - val_accuracy: 0.8662\nEpoch 35/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.3115 - accuracy: 0.9062 - val_loss: 0.4533 - val_accuracy: 0.8674\nEpoch 36/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.3090 - accuracy: 0.9069 - val_loss: 0.4507 - val_accuracy: 0.8691\nEpoch 37/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.2957 - accuracy: 0.9111 - val_loss: 0.4495 - val_accuracy: 0.8706\nEpoch 38/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.2900 - accuracy: 0.9128 - val_loss: 0.4481 - val_accuracy: 0.8700\nEpoch 39/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.2872 - accuracy: 0.9138 - val_loss: 0.4461 - val_accuracy: 0.8707\nEpoch 40/100\n125/125 [==============================] - 2s 13ms/step - loss: 0.2800 - accuracy: 0.9157 - val_loss: 0.4464 - val_accuracy: 0.8715\nEpoch 41/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.2720 - accuracy: 0.9181 - val_loss: 0.4465 - val_accuracy: 0.8719\nEpoch 42/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.2662 - accuracy: 0.9199 - val_loss: 0.4434 - val_accuracy: 0.8735\nEpoch 43/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.2628 - accuracy: 0.9208 - val_loss: 0.4441 - val_accuracy: 0.8726\nEpoch 44/100\n125/125 [==============================] - 2s 13ms/step - loss: 0.2565 - accuracy: 0.9232 - val_loss: 0.4422 - val_accuracy: 0.8741\nEpoch 45/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.2529 - accuracy: 0.9238 - val_loss: 0.4447 - val_accuracy: 0.8740\nEpoch 46/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.2428 - accuracy: 0.9272 - val_loss: 0.4426 - val_accuracy: 0.8739\nEpoch 47/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.2367 - accuracy: 0.9287 - val_loss: 0.4416 - val_accuracy: 0.8751\nEpoch 48/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.2390 - accuracy: 0.9279 - val_loss: 0.4445 - val_accuracy: 0.8751\nEpoch 49/100\n125/125 [==============================] - 2s 15ms/step - loss: 0.2298 - accuracy: 0.9306 - val_loss: 0.4457 - val_accuracy: 0.8753\nEpoch 50/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.2210 - accuracy: 0.9336 - val_loss: 0.4488 - val_accuracy: 0.8754\nEpoch 51/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.2209 - accuracy: 0.9333 - val_loss: 0.4499 - val_accuracy: 0.8753\nEpoch 52/100\n125/125 [==============================] - 2s 13ms/step - loss: 0.2152 - accuracy: 0.9348 - val_loss: 0.4494 - val_accuracy: 0.8760\nEpoch 53/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.2140 - accuracy: 0.9354 - val_loss: 0.4502 - val_accuracy: 0.8767\nEpoch 54/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.2062 - accuracy: 0.9377 - val_loss: 0.4556 - val_accuracy: 0.8765\nEpoch 55/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1989 - accuracy: 0.9400 - val_loss: 0.4527 - val_accuracy: 0.8769\nEpoch 56/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1981 - accuracy: 0.9401 - val_loss: 0.4547 - val_accuracy: 0.8781\nEpoch 57/100\n","name":"stdout"},{"output_type":"stream","text":"125/125 [==============================] - 2s 14ms/step - loss: 0.1925 - accuracy: 0.9415 - val_loss: 0.4545 - val_accuracy: 0.8775\nEpoch 58/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1861 - accuracy: 0.9438 - val_loss: 0.4610 - val_accuracy: 0.8773\nEpoch 59/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1831 - accuracy: 0.9441 - val_loss: 0.4649 - val_accuracy: 0.8762\nEpoch 60/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1794 - accuracy: 0.9456 - val_loss: 0.4636 - val_accuracy: 0.8770\nEpoch 61/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1758 - accuracy: 0.9473 - val_loss: 0.4656 - val_accuracy: 0.8785\nEpoch 62/100\n125/125 [==============================] - 2s 18ms/step - loss: 0.1729 - accuracy: 0.9471 - val_loss: 0.4653 - val_accuracy: 0.8776\nEpoch 63/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1699 - accuracy: 0.9484 - val_loss: 0.4676 - val_accuracy: 0.8784\nEpoch 64/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1631 - accuracy: 0.9503 - val_loss: 0.4779 - val_accuracy: 0.8766\nEpoch 65/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1607 - accuracy: 0.9510 - val_loss: 0.4784 - val_accuracy: 0.8780\nEpoch 66/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1572 - accuracy: 0.9520 - val_loss: 0.4788 - val_accuracy: 0.8776\nEpoch 67/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1526 - accuracy: 0.9535 - val_loss: 0.4835 - val_accuracy: 0.8771\nEpoch 68/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1486 - accuracy: 0.9545 - val_loss: 0.4879 - val_accuracy: 0.8775\nEpoch 69/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1464 - accuracy: 0.9554 - val_loss: 0.4887 - val_accuracy: 0.8774\nEpoch 70/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1431 - accuracy: 0.9561 - val_loss: 0.4930 - val_accuracy: 0.8773\nEpoch 71/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1382 - accuracy: 0.9576 - val_loss: 0.4961 - val_accuracy: 0.8776\nEpoch 72/100\n125/125 [==============================] - 2s 13ms/step - loss: 0.1375 - accuracy: 0.9578 - val_loss: 0.5007 - val_accuracy: 0.8771\nEpoch 73/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1348 - accuracy: 0.9588 - val_loss: 0.5010 - val_accuracy: 0.8773\nEpoch 74/100\n125/125 [==============================] - 2s 15ms/step - loss: 0.1294 - accuracy: 0.9606 - val_loss: 0.5130 - val_accuracy: 0.8767\nEpoch 75/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1275 - accuracy: 0.9613 - val_loss: 0.5148 - val_accuracy: 0.8770\nEpoch 76/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1247 - accuracy: 0.9614 - val_loss: 0.5091 - val_accuracy: 0.8779\nEpoch 77/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1212 - accuracy: 0.9627 - val_loss: 0.5198 - val_accuracy: 0.8769\nEpoch 78/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1189 - accuracy: 0.9637 - val_loss: 0.5257 - val_accuracy: 0.8765\nEpoch 79/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1196 - accuracy: 0.9629 - val_loss: 0.5215 - val_accuracy: 0.8768\nEpoch 80/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1142 - accuracy: 0.9650 - val_loss: 0.5366 - val_accuracy: 0.8765\nEpoch 81/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1122 - accuracy: 0.9658 - val_loss: 0.5346 - val_accuracy: 0.8763\nEpoch 82/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1104 - accuracy: 0.9657 - val_loss: 0.5403 - val_accuracy: 0.8766\nEpoch 83/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1072 - accuracy: 0.9671 - val_loss: 0.5416 - val_accuracy: 0.8764\nEpoch 84/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1039 - accuracy: 0.9680 - val_loss: 0.5549 - val_accuracy: 0.8754\nEpoch 85/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.1018 - accuracy: 0.9684 - val_loss: 0.5541 - val_accuracy: 0.8752\nEpoch 86/100\n125/125 [==============================] - 2s 15ms/step - loss: 0.0999 - accuracy: 0.9691 - val_loss: 0.5575 - val_accuracy: 0.8753\nEpoch 87/100\n125/125 [==============================] - 2s 15ms/step - loss: 0.0976 - accuracy: 0.9696 - val_loss: 0.5635 - val_accuracy: 0.8753\nEpoch 88/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.0945 - accuracy: 0.9708 - val_loss: 0.5664 - val_accuracy: 0.8758\nEpoch 89/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.0926 - accuracy: 0.9715 - val_loss: 0.5663 - val_accuracy: 0.8757\nEpoch 90/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.0911 - accuracy: 0.9717 - val_loss: 0.5695 - val_accuracy: 0.8753\nEpoch 91/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.0895 - accuracy: 0.9723 - val_loss: 0.5716 - val_accuracy: 0.8748\nEpoch 92/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.0960 - accuracy: 0.9696 - val_loss: 0.5667 - val_accuracy: 0.8755\nEpoch 93/100\n125/125 [==============================] - 2s 15ms/step - loss: 0.0865 - accuracy: 0.9728 - val_loss: 0.5785 - val_accuracy: 0.8759\nEpoch 94/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.0834 - accuracy: 0.9740 - val_loss: 0.5869 - val_accuracy: 0.8758\nEpoch 95/100\n125/125 [==============================] - 2s 13ms/step - loss: 0.0821 - accuracy: 0.9745 - val_loss: 0.5872 - val_accuracy: 0.8753\nEpoch 96/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.0796 - accuracy: 0.9751 - val_loss: 0.5921 - val_accuracy: 0.8749\nEpoch 97/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.0787 - accuracy: 0.9755 - val_loss: 0.5938 - val_accuracy: 0.8748\nEpoch 98/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.0768 - accuracy: 0.9759 - val_loss: 0.5983 - val_accuracy: 0.8759\nEpoch 99/100\n125/125 [==============================] - 2s 14ms/step - loss: 0.0754 - accuracy: 0.9760 - val_loss: 0.6051 - val_accuracy: 0.8751\nEpoch 100/100\n125/125 [==============================] - 2s 15ms/step - loss: 0.0741 - accuracy: 0.9767 - val_loss: 0.6099 - val_accuracy: 0.8749\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.models.load_model(\"s2s\")\nencoder_inputs = model.input[0]  # input_1\nprint(encoder_inputs)\nprint(model.layers[2])\nencoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\nencoder_states = [state_h_enc, state_c_enc]\nencoder_model = keras.Model(encoder_inputs, encoder_states)\n\ndecoder_inputs = model.input[1]  # input_2\ndecoder_state_input_h = keras.Input(shape=(latent_dim,), name=\"input_3\")\ndecoder_state_input_c = keras.Input(shape=(latent_dim,), name=\"input_4\")\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\ndecoder_lstm = model.layers[3]\ndecoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n    decoder_inputs, initial_state=decoder_states_inputs\n)\ndecoder_states = [state_h_dec, state_c_dec]\ndecoder_dense = model.layers[4]\ndecoder_outputs = decoder_dense(decoder_outputs)\ndecoder_model = keras.Model(\n    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n)\n\n# Reverse-lookup token index to decode sequences back to\n# something readable.\nreverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\nreverse_target_char_index = dict((i, char) for char, i in target_token_index.items())","execution_count":16,"outputs":[{"output_type":"stream","text":"KerasTensor(type_spec=TensorSpec(shape=(None, None, 71), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n<tensorflow.python.keras.layers.recurrent_v2.LSTM object at 0x7f0a037ac150>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef decode_sequence(input_seq):\n    states_value = encoder_model.predict(input_seq)\n\n    target_seq = np.zeros((1, 1, num_decoder_tokens))\n    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n    \n    stop_condition = False\n    decoded_sentence = \"\"\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += sampled_char\n\n        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n            stop_condition = True\n\n        target_seq = np.zeros((1, 1, num_decoder_tokens))\n        target_seq[0, 0, sampled_token_index] = 1.0\n\n        states_value = [h, c]\n    return decoded_sentence","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for seq_index in range(20):\n    input_seq = encoder_input_data[seq_index : seq_index + 1]\n    decoded_sentence = decode_sequence(input_seq)\n    print(20*\"-\")\n    print(\"Input sentence:\", input_texts[seq_index])\n    print(\"Target sentence:\", target_texts[seq_index])\n    print(\"Decoded sentence:\", decoded_sentence)","execution_count":25,"outputs":[{"output_type":"stream","text":"--------------------\nInput sentence: Go.\nTarget sentence:  \tVa !\n\nDecoded sentence: Bouge !\n\n--------------------\nInput sentence: Go.\nTarget sentence:  \tMarche.\n\nDecoded sentence: Bouge !\n\n--------------------\nInput sentence: Go.\nTarget sentence:  \tBouge !\n\nDecoded sentence: Bouge !\n\n--------------------\nInput sentence: Hi.\nTarget sentence:  \tSalut !\n\nDecoded sentence: Salut !\n\n--------------------\nInput sentence: Hi.\nTarget sentence:  \tSalut.\n\nDecoded sentence: Salut !\n\n--------------------\nInput sentence: Run!\nTarget sentence:  \tCours !\n\nDecoded sentence: File !\n\n--------------------\nInput sentence: Run!\nTarget sentence:  \tCourez !\n\nDecoded sentence: File !\n\n--------------------\nInput sentence: Run!\nTarget sentence:  \tPrenez vos jambes à vos cous !\n\nDecoded sentence: File !\n\n--------------------\nInput sentence: Run!\nTarget sentence:  \tFile !\n\nDecoded sentence: File !\n\n--------------------\nInput sentence: Run!\nTarget sentence:  \tFilez !\n\nDecoded sentence: File !\n\n--------------------\nInput sentence: Run!\nTarget sentence:  \tCours !\n\nDecoded sentence: File !\n\n--------------------\nInput sentence: Run!\nTarget sentence:  \tFuyez !\n\nDecoded sentence: File !\n\n--------------------\nInput sentence: Run!\nTarget sentence:  \tFuyons !\n\nDecoded sentence: File !\n\n--------------------\nInput sentence: Run.\nTarget sentence:  \tCours !\n\nDecoded sentence: File !\n\n--------------------\nInput sentence: Run.\nTarget sentence:  \tCourez !\n\nDecoded sentence: File !\n\n--------------------\nInput sentence: Run.\nTarget sentence:  \tPrenez vos jambes à vos cous !\n\nDecoded sentence: File !\n\n--------------------\nInput sentence: Run.\nTarget sentence:  \tFile !\n\nDecoded sentence: File !\n\n--------------------\nInput sentence: Run.\nTarget sentence:  \tFilez !\n\nDecoded sentence: File !\n\n--------------------\nInput sentence: Run.\nTarget sentence:  \tCours !\n\nDecoded sentence: File !\n\n--------------------\nInput sentence: Run.\nTarget sentence:  \tFuyez !\n\nDecoded sentence: File !\n\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}